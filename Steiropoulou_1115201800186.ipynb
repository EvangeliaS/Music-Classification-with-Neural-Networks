{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E3IEwAW4lir"
      },
      "source": [
        "# Αναγνώριση Προτύπων - Μηχανική Μάθηση 3η Εργασία\n",
        "## Στειροπούλου Ευαγγελία \n",
        "### 1115201800186"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFkkiAGv4li5"
      },
      "source": [
        "# FeedForward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzuja9jw4ljB"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbJmDdqq4ljK"
      },
      "source": [
        "## Load Data (mfccs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zP_A39N4ljP"
      },
      "outputs": [],
      "source": [
        "# path = os.getcwd()\n",
        "# print(path)\n",
        "\n",
        "path = '/content/gdrive/My Drive/Project3'\n",
        "\n",
        "#create the paths for the data\n",
        "training_data_path = path + '/data/music_genre_data_di/train/mfccs'\n",
        "test_data_path = path + '/data/music_genre_data_di/test/mfccs'\n",
        "validation_data_path = path + '/data/music_genre_data_di/val/mfccs'\n",
        "\n",
        "X_train = np.load(training_data_path + '/X.npy')\n",
        "y_train = np.load(training_data_path + '/labels.npy')\n",
        "X_val   = np.load(validation_data_path + '/X.npy')\n",
        "y_val   = np.load(validation_data_path + '/labels.npy')\n",
        "X_test  = np.load(test_data_path + '/X.npy')\n",
        "y_test  = np.load(test_data_path + '/labels.npy')\n",
        "\n",
        "# Μετατροπή των labels σε ακέραιους αριθμούς (0, 1, 2, 3)\n",
        "classes = np.unique(y_train)\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "y_train = np.array([class_to_idx[label] for label in y_train])\n",
        "y_val = np.array([class_to_idx[label] for label in y_val])\n",
        "y_test = np.array([class_to_idx[label] for label in y_test])\n",
        "\n",
        "# Δημιουργία των Tensor αντικειμένων από τα numpy arrays\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train.astype(np.float32)), torch.from_numpy(y_train))\n",
        "val_dataset = TensorDataset(torch.from_numpy(X_val.astype(np.float32)), torch.from_numpy(y_val))\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test.astype(np.float32)), torch.from_numpy(y_test))\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "validation_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Εμφάνιση των διαστάσεων των Tensor\n",
        "print(train_dataset.tensors[0].shape)\n",
        "print(train_dataset.tensors[1].shape)\n",
        "print(val_dataset.tensors[0].shape)\n",
        "print(val_dataset.tensors[1].shape)\n",
        "print(test_dataset.tensors[0].shape)\n",
        "print(test_dataset.tensors[1].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4UR4r3f4ljY"
      },
      "source": [
        "## Build Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_FW5zjl4ljb"
      },
      "outputs": [],
      "source": [
        "# # if we want to utilize the GPU (if available), we need to assign the model to the correct device\n",
        "# if torch.cuda.is_available():\n",
        "#   device=\"cuda\"\n",
        "# else:\n",
        "#     device=\"cpu\"\n",
        "\n",
        "# print (\"device=\",device)\n",
        "\n",
        "class FullyConnectedNeuralNetwork(nn.Module): ##NeuralNetwork iS A subclass of nn.module\n",
        "    def __init__(self):\n",
        "        super(FullyConnectedNeuralNetwork, self).__init__() ## call the constructor of super\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(26 , 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 4)\n",
        "        )\n",
        "\n",
        "    ## Every nn.Module subclass implements the operations on input data in the forward method.\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "device = \"cpu\"\n",
        "model = FullyConnectedNeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n",
        "# X = torch.rand(1, 26, device = device)  ##dummy data στην  GPU\n",
        "\n",
        "# # this call uses the forward function of the model along with some background operations.\n",
        "# # Notice that we do not explicitly call forward. This is handled by PyTorch.\n",
        "# log = model(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXaHI3564ljh"
      },
      "source": [
        "## Set Neural Network training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQiVfvit4ljm"
      },
      "outputs": [],
      "source": [
        "def train_network(model, optimizer, dataloader, loss_function, num_epochs):\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        print(\"Epoch: \", epoch)\n",
        "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
        "            # Transfer the data to the device (e.g., GPU) if available\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            outputs = model(data)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            \n",
        "            # Clear the gradients and compute new gradients (backward pass)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step() # Update the weights\n",
        "            \n",
        "            # per 100 batches report the value of the loss function on the training set\n",
        "            if batch_idx % 10 == 0:\n",
        "                loss, current = loss.item(), batch_idx * len(data)\n",
        "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    print('Training finished.')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGnhtXV24ljs"
      },
      "source": [
        "## Set evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jQDUzRf4ljv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, dataloader, loss_function):\n",
        "    model.eval()  # Put the model in evaluation mode\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predictions = model(data)\n",
        "            loss = loss_function(predictions, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_predictions.extend(predictions.argmax(1).cpu().detach().numpy())\n",
        "            all_targets.extend(targets.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    # Calculate F1 score, accuracy, and confusion matrix\n",
        "    f1_score_macro = f1_score(all_targets, all_predictions, average='macro')\n",
        "    accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    confusion_mat = confusion_matrix(all_targets, all_predictions)\n",
        "\n",
        "    return avg_loss, f1_score_macro, accuracy, confusion_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-us3rn1u4lj0"
      },
      "source": [
        "## Train Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybPZ_qpS4lj4"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "# Define the optimizer, learning rate, and loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 30\n",
        "\n",
        "# Train the model\n",
        "train_network(model, optimizer, train_dataloader, loss_function, num_epochs)\n",
        "\n",
        "# Evaluate the trained model\n",
        "avg_loss, f1_score_macro, accuracy, confusion_mat = evaluate_model(model, test_dataloader, loss_function)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Average Loss: {avg_loss}\")\n",
        "print(f\"F1 Score (Macro): {f1_score_macro}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(device)\n",
        "\n",
        "# Return the trained model\n",
        "trained_model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7t8lF3Z4lj8"
      },
      "source": [
        "## Train Network with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-tvFSLB4lj9"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "# if we want to utilize the GPU (if available), we need to assign the model to the correct device\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device=\"cuda\"\n",
        "    print(\"GPU available\")\n",
        "else:\n",
        "    device=\"cpu\"\n",
        "\n",
        "print (\"device=\",device)\n",
        "model = FullyConnectedNeuralNetwork().to(device)\n",
        "\n",
        "# Define the optimizer, learning rate, and loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 30\n",
        "\n",
        "# Train the model\n",
        "train_network(model, optimizer, train_dataloader, loss_function, num_epochs)\n",
        "\n",
        "# Evaluate the trained model\n",
        "avg_loss, f1_score_macro, accuracy, confusion_mat = evaluate_model(model, test_dataloader, loss_function)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Average Loss: {avg_loss}\")\n",
        "print(f\"F1 Score (Macro): {f1_score_macro}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Return the trained model\n",
        "trained_model = model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}