{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Αναγνώριση Προτύπων - Μηχανική Μάθηση 3η Εργασία\n",
    "## Στειροπούλου Ευαγγελία \n",
    "### 1115201800186"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeedForward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch) (4.6.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.venv/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.venv/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.venv/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.venv/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.venv/lib/python3.8/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.venv/lib/python3.8/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (44.0.0)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: cmake in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.8/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in ./.venv/lib/python3.8/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.8/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (4.6.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.venv/lib/python3.8/site-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (44.0.0)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.40.0)\n",
      "Requirement already satisfied: cmake in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.26.3)\n",
      "Requirement already satisfied: lit in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.venv/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.venv/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install -U scikit-learn\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eva/Documents/machine_learning/Project3\n",
      "torch.Size([3200, 26])\n",
      "torch.Size([3200])\n",
      "torch.Size([800, 26])\n",
      "torch.Size([800])\n",
      "torch.Size([1376, 26])\n",
      "torch.Size([1376])\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#create the paths for the data\n",
    "training_data_path = path + '/data/music_genre_data_di/train/mfccs'\n",
    "test_data_path = path + '/data/music_genre_data_di/test/mfccs'\n",
    "validation_data_path = path + '/data/music_genre_data_di/val/mfccs'\n",
    "\n",
    "X_train = np.load(training_data_path + '/X.npy')\n",
    "y_train = np.load(training_data_path + '/labels.npy')\n",
    "X_val   = np.load(validation_data_path + '/X.npy')\n",
    "y_val   = np.load(validation_data_path + '/labels.npy')\n",
    "X_test  = np.load(test_data_path + '/X.npy')\n",
    "y_test  = np.load(test_data_path + '/labels.npy')\n",
    "\n",
    "# Μετατροπή των labels σε ακέραιους αριθμούς (0, 1, 2, 3)\n",
    "classes = np.unique(y_train)\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "y_train = np.array([class_to_idx[label] for label in y_train])\n",
    "y_val = np.array([class_to_idx[label] for label in y_val])\n",
    "y_test = np.array([class_to_idx[label] for label in y_test])\n",
    "\n",
    "# Δημιουργία των Tensor αντικειμένων από τα numpy arrays\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_dataset   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "test_dataset  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Εμφάνιση των διαστάσεων των Tensor\n",
    "print(train_dataset.tensors[0].shape)\n",
    "print(train_dataset.tensors[1].shape)\n",
    "print(val_dataset.tensors[0].shape)\n",
    "print(val_dataset.tensors[1].shape)\n",
    "print(test_dataset.tensors[0].shape)\n",
    "print(test_dataset.tensors[1].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n",
      "FullyConnectedNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=26, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# if we want to utilize the GPU (if available), we need to assign the model to the correct device\n",
    "if torch.cuda.is_available():\n",
    "  device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "\n",
    "print (\"device=\",device)\n",
    "\n",
    "class FullyConnectedNeuralNetwork(nn.Module): ##NeuralNetwork iS A subclass of nn.module\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNeuralNetwork, self).__init__() ## call the constructor of super\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(26, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),    \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4),     \n",
    "        )\n",
    "\n",
    "    ## Every nn.Module subclass implements the operations on input data in the forward method.\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = FullyConnectedNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Neural Network training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, dataloader, loss_function, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "            # Transfer the data to the device (e.g., GPU) if available\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Perform the forward pass to obtain predictions\n",
    "            outputs = model(data)\n",
    "            print(outputs.shape)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "            \n",
    "            # Clear the gradients and compute new gradients (backward pass)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Print the loss for every 10th batch\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                avg_loss = running_loss / 10\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {avg_loss:.4f}')\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print('Training finished.')\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, loss_function):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            print(\"eval\",outputs.shape)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Calculate F1 score, accuracy, and confusion matrix\n",
    "    f1_score_macro = f1_score(all_targets, all_predictions, average='macro')\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    confusion_mat = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    return avg_loss, f1_score_macro, accuracy, confusion_mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_network(model, optimizer, train_dataloader, loss_function, num_epochs)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Evaluate the trained model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m avg_loss, f1_score_macro, accuracy, confusion_mat \u001b[39m=\u001b[39m evaluate_model(model, test_dataloader, loss_function)\n",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(model, optimizer, dataloader, loss_function, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Perform the forward pass to obtain predictions\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/machine_learning/Project3/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[28], line 24\u001b[0m, in \u001b[0;36mFullyConnectedNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[0;32m---> 24\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_relu_stack(x)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/Documents/machine_learning/Project3/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/machine_learning/Project3/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/machine_learning/Project3/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/machine_learning/Project3/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# Define the optimizer, learning rate, and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Train the model\n",
    "train_network(model, optimizer, train_dataloader, loss_function, num_epochs)\n",
    "\n",
    "# Evaluate the trained model\n",
    "avg_loss, f1_score_macro, accuracy, confusion_mat = evaluate_model(model, test_dataloader, loss_function)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Average Loss: {avg_loss}\")\n",
    "print(f\"F1 Score (Macro): {f1_score_macro}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Return the trained model\n",
    "trained_model = model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
